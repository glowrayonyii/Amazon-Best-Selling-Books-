{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df29ec5",
   "metadata": {},
   "source": [
    "## UNVEILING THE POWER OF BOOKS: AMAZON BEST BOOK SELLERS 2009-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d722dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a354ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda00212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the url has a consistent pattern over the years, we will be looping through urls to extract our data\n",
    "\n",
    "urls =[] #initialize an empty list to append the urls\n",
    "years = [str(i) for i in range(2009,2020)]\n",
    "for year in years:\n",
    "    urls.append (f\"https://www.amazon.com/gp/bestsellers/{year}/books/ref=zg_bsar_cal_ye\")\n",
    "    urls.append(f\"https://www.amazon.com/gp/bestsellers/{year}/books/ref=zg_bsar_pg_2_books/ref=zg_bsar_pg_2_books?ie=UTF8&pg=2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78ba69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to extract each elements.\n",
    "\n",
    "def get_dir(book,year): \n",
    "    '''to get the details of each book for each year''' \n",
    "    \n",
    "    import numpy as np\n",
    "    '''to get the name of price'''\n",
    "    \n",
    "    try:\n",
    "        Ranks = book.find('span', class_='zg-bdg-text').text[1:]\n",
    "    except Exception as err:\n",
    "        Ranks = np.nan\n",
    "    try:\n",
    "        Title = book.find('div',class_=\"_cDEzb_p13n-sc-css-line-clamp-1_1Fn1y\").text\n",
    "    except Exception as err:\n",
    "        Title = np.nan\n",
    "    try:\n",
    "        Authors = book.find('a',class_=\"a-size-small a-link-child\").text\n",
    "    except Exception as err:\n",
    "        Authors = np.nan\n",
    "    try:\n",
    "        Cover_type = book.find('span',class_=\"a-size-small a-color-secondary a-text-normal\").text\n",
    "    except Exception as err:\n",
    "        Cover_type = np.nan\n",
    "    \n",
    "    try:\n",
    "        Price = book.find('span',class_=\"_cDEzb_p13n-sc-price_3mJ9Z\").text[1:]\n",
    "    except Exception as err:\n",
    "        Price = np.nan\n",
    "    try:\n",
    "        Reviews  = book.find('span',class_=\"a-size-small\").text\n",
    "    except Exception as err:\n",
    "        Reviews = np.nan\n",
    "    try:\n",
    "        Ratings= book.find('span',class_=\"a-icon-alt\").text[:3] \n",
    "    except Exception as err:\n",
    "        Ratings = np.nan\n",
    "    Year = year\n",
    "    \n",
    "    return[Ranks, Title, Authors, Cover_type, Price, Reviews, Ratings, Year]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90c1a555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2009',\n",
       " '2009',\n",
       " '2010',\n",
       " '2010',\n",
       " '2011',\n",
       " '2011',\n",
       " '2012',\n",
       " '2012',\n",
       " '2013',\n",
       " '2013',\n",
       " '2014',\n",
       " '2014',\n",
       " '2015',\n",
       " '2015',\n",
       " '2016',\n",
       " '2016',\n",
       " '2017',\n",
       " '2017',\n",
       " '2018',\n",
       " '2018',\n",
       " '2019',\n",
       " '2019']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialise a list of years\n",
    "year = [(str(i),str(i)) for i in range(2009,2020)] \n",
    "years = [j for i in year for j in i]\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a21a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize an empty list to extract the two pages using webdriver for all the books 2009-2019\n",
    "\n",
    "all_books = [] \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "for url in urls: \n",
    "    \n",
    "    webpage = url\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    driver.get(webpage)        \n",
    "    \n",
    "    sleep(60)                 \n",
    "    \n",
    "    the_soup = BeautifulSoup(driver.page_source, 'html.parser')           \n",
    "    books = the_soup.find_all(id = 'gridItemRoot')                \n",
    "    \n",
    "    all_books.append(books) \n",
    "    \n",
    "    \n",
    "    \n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab7077de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '2009'),\n",
       " (1, '2009'),\n",
       " (2, '2010'),\n",
       " (3, '2010'),\n",
       " (4, '2011'),\n",
       " (5, '2011'),\n",
       " (6, '2012'),\n",
       " (7, '2012'),\n",
       " (8, '2013'),\n",
       " (9, '2013'),\n",
       " (10, '2014'),\n",
       " (11, '2014'),\n",
       " (12, '2015'),\n",
       " (13, '2015'),\n",
       " (14, '2016'),\n",
       " (15, '2016'),\n",
       " (16, '2017'),\n",
       " (17, '2017'),\n",
       " (18, '2018'),\n",
       " (19, '2018'),\n",
       " (20, '2019'),\n",
       " (21, '2019')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_index = (list(enumerate(years)))\n",
    "y = year_index\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1d0faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = [] \n",
    "for i in y:  \n",
    "    for books in all_books[i[0]]:             \n",
    "        for book in books:                   \n",
    "            scraped_data.append(get_dir(book,i[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae39d994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranks</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Book_cover</th>\n",
       "      <th>Price</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Lost Symbol (Robert Langdon)</td>\n",
       "      <td>Dan Brown</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>15.41</td>\n",
       "      <td>29,023</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Shack: Where Tragedy Confronts Eternity</td>\n",
       "      <td>William P. Young</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>10.14</td>\n",
       "      <td>41,129</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Liberty and Tyranny: A Conservative Manifesto</td>\n",
       "      <td>Mark R. Levin</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>14.76</td>\n",
       "      <td>5,341</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Breaking Dawn (The Twilight Saga, Book 4)</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>19.55</td>\n",
       "      <td>25,427</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Going Rogue: An American Life</td>\n",
       "      <td>Sarah Palin</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1,598</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ranks                                          Title           Authors  \\\n",
       "0     1               The Lost Symbol (Robert Langdon)         Dan Brown   \n",
       "1     2    The Shack: Where Tragedy Confronts Eternity  William P. Young   \n",
       "2     3  Liberty and Tyranny: A Conservative Manifesto     Mark R. Levin   \n",
       "3     4      Breaking Dawn (The Twilight Saga, Book 4)   Stephenie Meyer   \n",
       "4     5                  Going Rogue: An American Life       Sarah Palin   \n",
       "\n",
       "  Book_cover  Price Reviews Ratings  Year  \n",
       "0  Hardcover  15.41  29,023     4.3  2009  \n",
       "1  Paperback  10.14  41,129     4.6  2009  \n",
       "2  Hardcover  14.76   5,341     4.8  2009  \n",
       "3  Hardcover  19.55  25,427     4.7  2009  \n",
       "4  Hardcover   6.30   1,598     4.6  2009  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe\n",
    "\n",
    "df_books = pd.DataFrame(scraped_data, columns = [\n",
    "                         'Ranks',\n",
    "                         'Title',\n",
    "                         'Authors',\n",
    "                         'Book_cover',\n",
    "                         'Price',\n",
    "                         'Reviews',\n",
    "                         'Ratings',\n",
    "                       'Year'])\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595f72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.to_csv('Amazon Books 2009-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2222e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
